"""
KoGPT2 ê¸°ë°˜ ë ˆì‹œí”¼ ì±—ë´‡ (ìˆ˜ì •ëœ ë²„ì „) - ìƒì„± ë¬¸ì œ í•´ê²°
"""
import json
import torch
import os
import re
from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast
from config_kogpt2 import *

class KoGPT2RecipeChatbot:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ìƒíƒœ ì¶”ì 
        self.model_loaded = False
        self.is_trained_model = False
        
        self.load_model()
        self.load_recipe_data()
    
    def check_trained_model_exists(self):
        """í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        required_files = [
            'config.json',
            'pytorch_model.bin',
            'tokenizer.json',
            'tokenizer_config.json'
        ]
        
        if not os.path.exists(MODEL_PATH):
            print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            return False
        
        missing_files = []
        for file in required_files:
            file_path = os.path.join(MODEL_PATH, file)
            if not os.path.exists(file_path):
                if file == 'pytorch_model.bin':
                    alt_path = os.path.join(MODEL_PATH, 'model.safetensors')
                    if os.path.exists(alt_path):
                        continue
                missing_files.append(file)
        
        if missing_files:
            print(f"âŒ ëˆ„ë½ëœ ëª¨ë¸ íŒŒì¼ë“¤: {missing_files}")
            return False
        
        print("âœ… í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•©ë‹ˆë‹¤")
        return True
    
    def load_model(self):
        """í›ˆë ¨ëœ KoGPT2 ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
        
        if self.check_trained_model_exists():
            print("ğŸ“‚ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
            
            try:
                self.model = GPT2LMHeadModel.from_pretrained(
                    MODEL_PATH,
                    local_files_only=True
                )
                self.tokenizer = PreTrainedTokenizerFast.from_pretrained(
                    MODEL_PATH,
                    local_files_only=True
                )
                
                self.model.to(self.device)
                self.model.eval()
                
                # íŒ¨ë”© í† í° ì„¤ì •
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                
                self.model_loaded = True
                self.is_trained_model = True
                
                print("âœ… í›ˆë ¨ëœ KoGPT2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                print(f"  - EOS í† í° ID: {self.tokenizer.eos_token_id}")
                print(f"  - PAD í† í° ID: {self.tokenizer.pad_token_id}")
                
                return
                
            except Exception as e:
                print(f"âŒ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”„ ê¸°ë³¸ ëª¨ë¸ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
        print("ğŸ“‚ ê¸°ë³¸ KoGPT2 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
        
        try:
            self.model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)
            self.tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)
            
            self.model.to(self.device)
            self.model.eval()
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.model_loaded = True
            self.is_trained_model = False
            
            print("âœ… ê¸°ë³¸ KoGPT2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print("âš ï¸ ì£¼ì˜: í›ˆë ¨ë˜ì§€ ì•Šì€ ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {e}")
            self.model_loaded = False
            raise e
    
    def load_recipe_data(self):
        """ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(RAW_DATA_PATH, 'r', encoding='utf-8') as f:
                self.recipes = json.load(f)
            print(f"ğŸ“š ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ: {len(self.recipes)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ë ˆì‹œí”¼ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.recipes = []
    
    def clean_generated_text(self, text):
        """ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬"""
        # EOS í† í°ì—ì„œ ìë¥´ê¸°
        if '<|endoftext|>' in text:
            text = text.split('<|endoftext|>')[0]
        
        # ì´ìƒí•œ í† í° íŒ¨í„´ ì œê±°
        text = re.sub(r'<\|[^>]*\|>', '', text)
        text = re.sub(r'[<>|{}]+', '', text)
        
        # ë°˜ë³µë˜ëŠ” êµ¬ë‘ì ì´ë‚˜ ë¬¸ì ì œê±°
        text = re.sub(r'([.!?])\1{2,}', r'\1', text)
        text = re.sub(r'(\w)\1{4,}', r'\1', text)
        
        # ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì •ë¦¬
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def generate_answer(self, question):
        """KoGPT2ë¡œ ë‹µë³€ ìƒì„± - ìˆ˜ì •ëœ ë²„ì „"""
        if not self.model_loaded:
            return None
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = PROMPT_FORMAT.format(question=question)
            
            # í† í¬ë‚˜ì´ì§•
            input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)
            
            # ì…ë ¥ ê¸¸ì´ ì œí•œ
            if input_ids.shape[1] > 500:  # ë” ì§§ê²Œ ì œí•œ
                input_ids = input_ids[:, -500:]
            
            # ìˆ˜ì •ëœ ìƒì„± íŒŒë¼ë¯¸í„°
            with torch.no_grad():
                output = self.model.generate(
                    input_ids,
                    max_new_tokens=300,  # max_length ëŒ€ì‹  max_new_tokens ì‚¬ìš©
                    temperature=0.8,
                    top_p=0.9,
                    top_k=50,
                    repetition_penalty=1.2,
                    do_sample=True,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    num_return_sequences=1,
                    use_cache=True
                )
            
            # ë””ì½”ë”©
            generated_text = self.tokenizer.decode(output[0], skip_special_tokens=False)
            
            # ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if "ë‹µë³€:" in generated_text:
                answer = generated_text.split("ë‹µë³€:")[-1]
                
                # í…ìŠ¤íŠ¸ ì •ë¦¬
                answer = self.clean_generated_text(answer)
                
                # ìµœì†Œ ê¸¸ì´ í™•ì¸ ë° í’ˆì§ˆ ì²´í¬
                if len(answer) > 10 and self.is_valid_answer(answer):
                    return answer
            
            return None
            
        except Exception as e:
            print(f"âŒ ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def is_valid_answer(self, text):
        """ìƒì„±ëœ ë‹µë³€ì´ ìœ íš¨í•œì§€ í™•ì¸"""
        # ë„ˆë¬´ ì§§ì€ ë‹µë³€
        if len(text) < 10:
            return False
        
        # ì˜ë¯¸ì—†ëŠ” í† í°ë“¤ë¡œë§Œ êµ¬ì„±ëœ ê²½ìš°
        if re.match(r'^[<>|{}\s]+$', text):
            return False
        
        # ë°˜ë³µì´ ë„ˆë¬´ ë§ì€ ê²½ìš°
        words = text.split()
        if len(words) < 3:
            return False
        
        # ê°™ì€ ë‹¨ì–´ê°€ ì—°ì†ìœ¼ë¡œ 3ë²ˆ ì´ìƒ ë‚˜ì˜¤ëŠ” ê²½ìš°
        for i in range(len(words) - 2):
            if words[i] == words[i+1] == words[i+2]:
                return False
        
        return True
    
    def find_recipe_by_name(self, question):
        """ìš”ë¦¬ ì´ë¦„ìœ¼ë¡œ ë ˆì‹œí”¼ ì°¾ê¸°"""
        for recipe in self.recipes:
            if recipe['name'] in question:
                return recipe
        return None
    
    def find_recipes_by_ingredient(self, question):
        """ì¬ë£Œë¡œ ë ˆì‹œí”¼ ì°¾ê¸°"""
        matching_recipes = []
        for recipe in self.recipes:
            for ingredient in recipe['ingredients']:
                if len(ingredient) >= 2 and ingredient in question:
                    matching_recipes.append(recipe)
                    break
        return matching_recipes[:5]
    
    def format_complete_recipe(self, recipe):
        """ì™„ì „í•œ ë ˆì‹œí”¼ ì •ë³´ í¬ë§·íŒ…"""
        result = f"ğŸ³ **{recipe['name']}**\n\n"
        
        if recipe.get('category'):
            result += f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {recipe['category']}\n"
        if recipe.get('cooking_method'):
            result += f"ğŸ”¥ ì¡°ë¦¬ë²•: {recipe['cooking_method']}\n"
        
        if recipe['ingredients']:
            result += f"\nğŸ“‹ **ì¬ë£Œ ({len(recipe['ingredients'])}ê°œ):**\n"
            for i, ingredient in enumerate(recipe['ingredients'], 1):
                result += f"{i}. {ingredient}\n"
        
        if recipe['steps']:
            result += f"\nğŸ‘¨â€ğŸ³ **ì¡°ë¦¬ ê³¼ì • ({len(recipe['steps'])}ë‹¨ê³„):**\n"
            for i, step in enumerate(recipe['steps'], 1):
                result += f"{i}. {step}\n"
        
        return result
    
    def format_ingredients_only(self, recipe):
        """ì¬ë£Œë§Œ í‘œì‹œ"""
        if not recipe['ingredients']:
            return f"{recipe['name']}ì˜ ì¬ë£Œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        result = f"ğŸ¥¬ **{recipe['name']} ì¬ë£Œ ({len(recipe['ingredients'])}ê°œ):**\n\n"
        for i, ingredient in enumerate(recipe['ingredients'], 1):
            result += f"{i}. {ingredient}\n"
        
        return result
    
    def format_cooking_steps_only(self, recipe):
        """ì¡°ë¦¬ ê³¼ì •ë§Œ í‘œì‹œ"""
        if not recipe['steps']:
            return f"{recipe['name']}ì˜ ì¡°ë¦¬ ë°©ë²• ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        result = f"ğŸ‘¨â€ğŸ³ **{recipe['name']} ë§Œë“œëŠ” ë²• ({len(recipe['steps'])}ë‹¨ê³„):**\n\n"
        for i, step in enumerate(recipe['steps'], 1):
            result += f"{i}. {step}\n"
        
        return result
    
    def fallback_answer(self, question):
        """í´ë°± ë‹µë³€"""
        if not self.recipes:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ë ˆì‹œí”¼ ì´ë¦„ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰
        recipe = self.find_recipe_by_name(question)
        if recipe:
            if any(word in question for word in ['ë§Œë“¤', 'ì¡°ë¦¬', 'ë°©ë²•', 'ì–´ë–»ê²Œ', 'ê³¼ì •', 'ìˆœì„œ']):
                return self.format_cooking_steps_only(recipe)
            elif any(word in question for word in ['ì¬ë£Œ', 'ë“¤ì–´ê°€', 'í•„ìš”', 'ë„£ì–´']):
                return self.format_ingredients_only(recipe)
            else:
                return self.format_complete_recipe(recipe)
        
        # ì¬ë£Œë¡œ ê²€ìƒ‰
        matching_recipes = self.find_recipes_by_ingredient(question)
        if matching_recipes:
            if len(matching_recipes) == 1:
                return self.format_complete_recipe(matching_recipes[0])
            else:
                result = f"ğŸ” í•´ë‹¹ ì¬ë£Œë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë“¤:\n\n"
                for i, recipe in enumerate(matching_recipes, 1):
                    result += f"{i}. **{recipe['name']}**\n"
                    if recipe['ingredients']:
                        preview_ingredients = recipe['ingredients'][:3]
                        result += f"   ì¬ë£Œ: {', '.join(preview_ingredients)}"
                        if len(recipe['ingredients']) > 3:
                            result += f" ì™¸ {len(recipe['ingredients'])-3}ê°œ"
                        result += "\n"
                    result += "\n"
                
                result += "ğŸ’¡ êµ¬ì²´ì ì¸ ìš”ë¦¬ ì´ë¦„ì„ ë§ì”€í•˜ì‹œë©´ ìì„¸í•œ ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ë“œë ¤ìš”!"
                return result
        
        # ì¼ë°˜ì ì¸ ìš”ë¦¬ ì¶”ì²œ
        if any(word in question for word in ['ì¶”ì²œ', 'ë­', 'ë¬´ì—‡', 'ì–´ë–¤']):
            popular_recipes = self.recipes[:10]
            result = "ğŸ³ **ì¸ê¸° ìš”ë¦¬ ì¶”ì²œ:**\n\n"
            for i, recipe in enumerate(popular_recipes, 1):
                result += f"{i}. {recipe['name']}"
                if recipe.get('category'):
                    result += f" ({recipe['category']})"
                result += "\n"
            
            result += "\nğŸ’¡ ì›í•˜ì‹œëŠ” ìš”ë¦¬ ì´ë¦„ì„ ë§ì”€í•˜ì‹œë©´ ìì„¸í•œ ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ë“œë ¤ìš”!"
            return result
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë ˆì‹œí”¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ ì´ë ‡ê²Œ ë¬¼ì–´ë³´ì„¸ìš”:\nâ€¢ 'ê¹€ì¹˜ì°Œê°œ ì–´ë–»ê²Œ ë§Œë“¤ì–´?'\nâ€¢ 'ë¶ˆê³ ê¸° ì¬ë£Œê°€ ë­ì•¼?'\nâ€¢ 'ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?'"
    
    def chat(self, question):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€"""
        if not question.strip():
            return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë ˆì‹œí”¼ë‚˜ ìš”ë¦¬ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ³"
        
        # ì¸ì‚¬ë§ ì²˜ë¦¬
        if any(word in question for word in ['ì•ˆë…•', 'í—¬ë¡œ', 'ì²˜ìŒ', 'ë°˜ê°€ì›Œ']):
            model_status = "í›ˆë ¨ëœ ëª¨ë¸" if self.is_trained_model else "ê¸°ë³¸ ëª¨ë¸"
            return f"ì•ˆë…•í•˜ì„¸ìš”! KoGPT2 ë ˆì‹œí”¼ ì±—ë´‡ì…ë‹ˆë‹¤ ({model_status}). ìš”ë¦¬ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ³\n\nğŸ’¡ ì˜ˆì‹œ:\nâ€¢ 'ê¹€ì¹˜ì°Œê°œ ì–´ë–»ê²Œ ë§Œë“¤ì–´?'\nâ€¢ 'ë¶ˆê³ ê¸° ì¬ë£Œê°€ ë­ì•¼?'\nâ€¢ 'ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?'"
        
        # ë„ì›€ë§ ì²˜ë¦¬
        if any(word in question for word in ['ë„ì›€', 'ì‚¬ìš©ë²•', 'ëª…ë ¹ì–´']):
            return "ğŸ“– **ì‚¬ìš© ë°©ë²•:**\n\nğŸ³ **ì¡°ë¦¬ë²• ì§ˆë¬¸:**\nâ€¢ 'ê¹€ì¹˜ì°Œê°œ ì–´ë–»ê²Œ ë§Œë“¤ì–´?'\nâ€¢ 'ë¶ˆê³ ê¸° ë§Œë“œëŠ” ë°©ë²•'\nâ€¢ 'ëœì¥ì°Œê°œ ì¡°ë¦¬ë²•'\n\nğŸ¥¬ **ì¬ë£Œ ì§ˆë¬¸:**\nâ€¢ 'ê¹€ì¹˜ì°Œê°œ ì¬ë£Œê°€ ë­ì•¼?'\nâ€¢ 'ë¶ˆê³ ê¸°ì— ë­ê°€ ë“¤ì–´ê°€?'\n\nğŸ” **ìš”ë¦¬ ê²€ìƒ‰:**\nâ€¢ 'ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?'\nâ€¢ 'ë‹­ê³ ê¸° ìš”ë¦¬ ì¶”ì²œ'\n\nëª¨ë“  ì¡°ë¦¬ ê³¼ì •ê³¼ ì¬ë£Œë¥¼ ì™„ì „íˆ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤!"
        
        # KoGPT2ë¡œ ë‹µë³€ ìƒì„± ì‹œë„ (í›ˆë ¨ëœ ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ)
        if self.is_trained_model:
            answer = self.generate_answer(question)
            
            if answer and len(answer.strip()) > 10:
                # ìƒì„±ëœ ë‹µë³€ì´ ìœ íš¨í•˜ë©´ ë°˜í™˜
                return answer
            else:
                print("âš ï¸ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨ - í´ë°± ë‹µë³€ ì‚¬ìš©")
        else:
            print("â„¹ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© - í´ë°± ë‹µë³€ ì‚¬ìš©")
        
        # í´ë°± ë‹µë³€
        return self.fallback_answer(question)

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("ğŸ¤– ìˆ˜ì •ëœ KoGPT2 ë ˆì‹œí”¼ ì±—ë´‡ í…ŒìŠ¤íŠ¸!")
    print("=" * 60)
    
    chatbot = KoGPT2RecipeChatbot()
    
    test_questions = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ê¹€ì¹˜ì°Œê°œ ì–´ë–»ê²Œ ë§Œë“¤ì–´?",
        "ê¹€ì¹˜ì°Œê°œ ì¬ë£Œê°€ ë­ì•¼?",
        "ê°ìë¡œ ë­ ë§Œë“¤ ìˆ˜ ìˆì–´?",
        "ìš”ë¦¬ ì¶”ì²œí•´ì¤˜",
        "ë„ì›€ë§",
        "ì•½ê³¼ ë§Œë“œëŠ” ë°©ë²•",
        "ì²­êµ­ì¥ ë§Œë“œëŠ” ë°©ë²•",
        "ë¶€ëŒ€ì°Œê°œ ë§Œë“œëŠ” ë°©ë²•",
        "ë¶€ëŒ€ì°Œê°œ ì¬ë£Œ",
        "ì¹¼êµ­ìˆ˜ ë§Œë“œëŠ” ë°©ë²• ìì„¸íˆ"
    ]
    
    for question in test_questions:
        print(f"\nğŸ’¬ Q: {question}")
        answer = chatbot.chat(question)
        print(f"ğŸ¤– A: {answer}")
        print("-" * 60)